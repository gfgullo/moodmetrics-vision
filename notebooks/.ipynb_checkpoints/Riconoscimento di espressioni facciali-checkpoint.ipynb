{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><center>Riconoscimento di espressioni facciali tramite una rete neurale convoluzionale</center></h3>\n",
    "<center><img src=\"res/logo.jpg\"/><center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Il problema\n",
    "Il riconoscimento delle emozioni umane da parte di un computer è un problema popolare ed affrontato in diversi modi come sentiment analysis di post e messaggi o analisi della voce.\n",
    "In questa ricerca proverò a riconoscere le emozioni espresse direttamente dal volto umano, riconoscendo automaticamente i tratti che più le caratterizzano tramite una rete neurale convoluzionale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Il dataset\n",
    "Il dataset consiste in 28.709 immagini di volti in grayscale formate da 48x48 pixel. Può essere scaricato (da qui)[\n",
    "Il file train.csv contiene due colonne\n",
    "* **Pixels**: L'intensità di ogni pixel per ogni immagine spacchettati in un unica stringa\n",
    "* **Emotion**: Un'intero da 0 a 6 che rappresenta l'emozione espressa dalla foto (*0=Arrabiato, 1=Disgustato, 2=Spaventato, 3=Felice, 4=Triste, 5=Sorpreso, 6=Neutrale*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apro e carico il dataset all'interno di un DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>pixels</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion                                             pixels     Usage\n",
       "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n",
       "1        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n",
       "2        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n",
       "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n",
       "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "faces = pd.read_csv(\"data/fer2013.csv\")\n",
    "faces.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifico che il dataset sia bilanciato, ovvero che delle classi non contengano un numero di esempi notevolmente superiore/inferiore rispetto alle altre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    8989\n",
       "6    6198\n",
       "4    6077\n",
       "2    5121\n",
       "0    4953\n",
       "5    4002\n",
       "1     547\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faces.emotion.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il dataset è notevolmente sbilanciato, il numero di volti felici è nell'ordine di 15 volte maggiore rispetto a quelli disgustati."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# La soluzione\n",
    "Le reti neurali ricorrenti sono uno standard de-facto per quanto riguarda il riconoscimento digitale di immagini.\n",
    "Nella mia soluzione ho sviluppato una rete neurale ricorrente profonda per identificare automaticamente i tratti del volto che ne rappresentano lo stato d'animo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importo tutte le dipendenze utilizzate per il progetto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import keras\n",
    "from keras.models import load_model\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Preprocessing dell'immagine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per testare l'algoritmo utilizzerò 6 mie foto, le immagini vengono trattate come grayscale ed i canali aggiuntivi vengono scartati, per mantenere lo standard del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('happy.jpg',0)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ricerco un volto all'interno dell'immagine, se lo trovo lo estraggo ritagliando l'immagine intorno ad esso. Per far questo in maniera semplice utilizzo la libreria **[OpenCV](https://opencv.org/)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_face(img):\n",
    "    haar_face_cascade = cv2.CascadeClassifier('data/haarcascade_frontalface_alt.xml')\n",
    "    faces = haar_face_cascade.detectMultiScale(img, scaleFactor=1.1, minNeighbors=5);\n",
    "    if(len(faces)==0):\n",
    "        return img,False\n",
    "    x,y,w,h=faces[0]\n",
    "    return img[y:y+h, x:x+w],True\n",
    "\n",
    "img = cv2.imread('data/happy.jpg',0)\n",
    "face_img,found=extract_face(img)\n",
    "if(not found):\n",
    "    print(\"Nessun volto rilevato\")\n",
    "else:\n",
    "    plt.imshow(face_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Addestramento della rete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per creare la mia rete utilizzo **[Keras](https://keras.io/)** con **[Tensorlow](https://www.tensorflow.org/)** come backend.\n",
    "\n",
    "Il processo di addestramento di una rete convoluzionale profonda è dispendioso sia in termini di tempo che di risorse, per questo ho proceduto ad addestrare la rete in cloud su un clouster di GPU Nvidia utilizzando **[Amazon EC2 Spot Instances](https://aws.amazon.com/ec2/spot/)** per tagliare i costi di addestramento al minimo.\n",
    "\n",
    "L'addestramento ha richiesto circa un'ora e mezza ed ha ottenuto una *test accuracy* del **75,7%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carico il modello di rete neurale convoluzionare precedentemente addestrata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"facexp_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrivo una helper function per stampare su schermo il risultato della predizione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_prediction(prediction):\n",
    "    EMOTIONS = [\"arrabbiato\",\"disgustato\",\"spaventato\",\"felice\",\"triste\",\"sorpreso\",\"neutrale\"]\n",
    "    print(\"Il soggetto è \"+EMOTIONS[np.argmax(prediction)]+\" con una probabilità del \"+str(max(prediction[0])*100)+\"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizzo la mia rete per effettuare la classificazione e predirre l'umore del soggetto dall'espressione facciale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('data/happy.jpg',0)\n",
    "face_img,found = extract_face(img)\n",
    "\n",
    "if(not found):\n",
    "    print(\"Nessun volto rilevato\")\n",
    "\n",
    "else:\n",
    "    plt.imshow(face_img)\n",
    "\n",
    "    face_img = cv2.resize(face_img, (48, 48)) #Ridimensiono a 48x48 per far combaciare con il dataset\n",
    "\n",
    "    imgs = np.array([face_img])\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        imgs = imgs.reshape(imgs.shape[0], 1, 48, 48)\n",
    "    else:\n",
    "        imgs = imgs.reshape(imgs.shape[0], 48, 48, 1)\n",
    "\n",
    "    prediction=model.predict(imgs)\n",
    "    show_prediction(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WORK IN PROGRESS..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
